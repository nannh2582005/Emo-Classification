\chapter{XÂY DỰNG MÔ HÌNH PHÂN TÍCH}

\section{Các thư viện chính}
\subsection{Module Loader}

Hệ thống sử dụng các thư viện mã nguồn mở sau:

\begin{itemize}
    \item \textbf{Scikit-learn (sklearn):} 
    Thư viện cốt lõi dùng để xây dựng các mô hình học máy như 
    \textit{Logistic Regression}, \textit{Naive Bayes} và \textit{SVM}. 
    Thư viện cung cấp đầy đủ công cụ để:
    \begin{itemize}
        \item trích xuất đặc trưng văn bản bằng \textit{TF--IDF Vectorizer};
        \item tiền xử lý dữ liệu (train--test split, chuẩn hóa);
        \item huấn luyện và đánh giá mô hình.
    \end{itemize}

    Các tham số quan trọng thường dùng:
    \begin{itemize}
        \item \texttt{C} (SVM): điều chỉnh mức phạt khi mô hình phân loại sai;
        \item \texttt{kernel} (SVM): lựa chọn hàm nhân (\textit{linear}, \textit{rbf}, \dots);
        \item \texttt{alpha} (Naive Bayes): hệ số làm trơn Laplace;
        \item \texttt{max\_features} (TF--IDF): giới hạn số lượng đặc trưng.
    \end{itemize}

    \item \textbf{Pandas:} 
    Dùng để đọc dữ liệu từ các định dạng như \texttt{.csv} và \texttt{.xlsx},
    đồng thời hỗ trợ thao tác linh hoạt trên \textit{DataFrame} 
    (lọc, gộp, thống kê, biến đổi dữ liệu).

    Tham số quan trọng:
    \begin{itemize}
        \item \texttt{read\_csv()}, \texttt{read\_excel()}: đọc dữ liệu;
        \item \texttt{dropna()}: loại bỏ hàng bị thiếu;
        \item \texttt{astype()}: chuyển kiểu dữ liệu.
    \end{itemize}

    \item \textbf{PyVi:}
    Thư viện xử lý tiếng Việt chuyên dụng, dùng để tách từ (\textit{tokenization}),
    giúp văn bản tiếng Việt được phân chia theo cụm từ có nghĩa trước khi đưa vào mô hình. 
    Điều này cải thiện độ chính xác của TF--IDF và mô hình phân loại.

    Phương thức chính:
    \begin{itemize}
        \item \texttt{ViTokenizer.tokenize(sentence)}: tách từ trong câu đầu vào.
    \end{itemize}

    \item \textbf{Joblib:}
    Dùng để tuần tự hóa (serialize) mô hình đã huấn luyện và lưu xuống đĩa,
    cho phép tái sử dụng mô hình mà không cần huấn luyện lại.

    Hàm quan trọng:
    \begin{itemize}
        \item \texttt{joblib.dump(model, path)}: lưu mô hình;
        \item \texttt{joblib.load(path)}: tải mô hình.
    \end{itemize}

    \item \textbf{Matplotlib \& Seaborn:}
    Hai thư viện trực quan hóa dữ liệu giúp vẽ các biểu đồ thống kê 
    và ma trận nhầm lẫn (\textit{Confusion Matrix}).  
    Trong đồ án, nhóm sử dụng chúng để đánh giá trực quan hiệu năng mô hình.

    Các hàm phổ biến:
    \begin{itemize}
        \item \texttt{plt.figure(figsize)}: tạo khung hình;
        \item \texttt{sns.heatmap()}: vẽ ma trận nhầm lẫn;
        \item \texttt{plt.xlabel()}, \texttt{plt.ylabel()}: thêm nhãn trục.
    \end{itemize}

    \item \textbf{OpenPyXL:}
    Thư viện hỗ trợ đọc và ghi dữ liệu vào định dạng Excel (\texttt{.xlsx}),
    được sử dụng khi bộ dữ liệu ban đầu ở dạng Excel hoặc khi cần xuất dữ liệu đã xử lý.

    Hàm quan trọng:
    \begin{itemize}
        \item \texttt{load\_workbook()}: đọc file Excel;
        \item \texttt{worksheet.append()}: thêm dòng dữ liệu;
        \item \texttt{workbook.save()}: lưu tệp Excel.
    \end{itemize}

\end{itemize}

%-----------------------------------
\section{Module Preprocessor}

Tiền xử lý là một bước thiết yếu trước khi đi vào quá trình huấn luyện mô hình. Đặc biệt hơn, trong môi trường trực tuyến trên mạng xã hội, các tài liệu thường không được viết bằng văn bản chính thức. Điều này đặc biệt đúng với thanh thiếu niên, những người thường sử dụng nhiều biểu tượng cảm xúc, dạng rút gọn của từ, ký hiệu và ký tự đặc biệt, từ viết sai chính tả, lỗi ngữ pháp, hoặc từ ghép. Trước khi được đưa vào mô hình, dữ liệu phải trải qua các bước tiền xử lý cần thiết.

\subsection{Xóa các ký tự đặc biệt}
Các ký tự đặc biệt không mang ý nghĩa phân loại và có thể gây nhiễu trong quá trình phân tích.

\subsection{Chuyển về chữ thường}
Mỗi số và ký tự đặc biệt đều được biểu diễn bằng một dãy nhị phân trong bộ nhớ máy tính. Chữ in hoa và chữ thường có mã Unicode khác nhau, dù về mặt ngữ nghĩa là giống nhau, nhưng máy tính có thể không phân biệt được trong dữ liệu đầu vào, dẫn đến kết quả dự đoán bị ảnh hưởng. Do đó, việc chuyển tất cả chữ về dạng chữ thường là hợp lý cho hệ thống phân tích và dự đoán.

\subsection{Loại bỏ stopword}
Trong tiếng Việt là các từ như \textit{cái, các, cả, ...}. Các từ này thường sẽ được loại bỏ để giảm kích thước của bộ từ vựng. Nhóm dùng bộ dữ liệu stopword được tổng hợp bởi Van-Duyet Le.

\textbf{Link dữ liệu gốc:} \url{https://github.com/stopwords/vietnamese-stopwords}

\subsection{Unicode}
Chuẩn hóa dữ liệu về dạng Unicode.

\subsection{Gán nhãn dữ liệu}
Như đã trình bày ở mục 2.1.

\subsection{Xử lý dữ liệu khuyết}
Tập dữ liệu thu thập có thể chứa nhiều dòng dữ liệu trống, và dữ liệu trống không có ý nghĩa trong quá trình phân tích, gây lãng phí bộ nhớ lưu trữ. Đối với bản ghi bị khuyết nhãn, nhóm quy định gán nhãn \textbf{Other} (tức Trung tính) cho dữ liệu đó.

\subsection{Tokenization (tách từ)}
Tokenization là bước tách câu hoặc văn bản thành các đơn vị nhỏ hơn (token), thường là từ, cụm từ hoặc ký tự. Đây là bước quan trọng nhất trong xử lý ngôn ngữ tự nhiên vì hầu hết các phương pháp vectorization (One-hot, TF-IDF, ...) đều yêu cầu đầu vào là danh sách token.

Tiếng Việt là ngôn ngữ đơn lập, trong đó nhiều từ được cấu thành từ nhiều âm tiết và được phân tách bằng dấu cách (ví dụ: \textit{học sinh, công nghệ thông tin}). Do đó, việc tokenization đơn giản dựa trên dấu cách sẽ không đảm bảo được tính chính xác về mặt ngữ nghĩa. Để khắc phục hạn chế này, nhóm sử dụng \textbf{ViTokenizer} trong thư viện \texttt{pyvi}, một công cụ tokenization chuyên biệt cho tiếng Việt, có khả năng nhận diện và ghép các cụm từ đa âm tiết một cách chính xác. Đầu ra sau khi tokenize có dạng \textit{học\_sinh}, ...

\subsection{Mã hóa nhãn dán}
Chuyển nhãn dán thành các mã số từ 0 đến 2 tương ứng với:
\begin{itemize}
    \item 0: Tích cực
    \item 1: Tiêu cực
    \item 2: Trung tính
\end{itemize}

\subsection{Chuyển hóa emoji và teencode}
Trong các văn bản thu thập từ mạng xã hội, emoji xuất hiện với tần suất cao, đóng vai trò quan trọng trong việc thể hiện cảm xúc của người viết, đặc biệt đối với bài toán phân loại cảm xúc. Tuy nhiên, đa số mô hình học máy và các phương pháp biểu diễn đặc trưng không thể xử lý trực tiếp biểu tượng này. Vì vậy, việc chuyển hóa chúng thành văn bản có ý nghĩa là bước cần thiết nhằm bảo toàn thông tin cảm xúc và đảm bảo tính khả dụng của dữ liệu khi đưa vào mô hình.

\subsubsection{Chuyển hóa emoji}
Emoji có thể truyền tải cảm xúc rõ rệt. Nhóm thực hiện ánh xạ từng emoji sang một nhãn văn bản tương ứng, chẳng hạn:

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{images/emoji.png}
    \caption{Một số nhãn dán emoji minh họa}
    \label{fig:emoji_mapping}
\end{figure}

\subsubsection{Chuyển hóa teencode}
Teencode là hình thức viết tắt, biến thể hoặc mã hóa trong giao tiếp của giới trẻ. Nếu không chuẩn hóa, những từ này sẽ bị xem như token riêng biệt, làm tăng kích thước từ vựng và gây nhiễu. Nhóm xây dựng bảng từ điển teencode phổ biến và thực hiện ánh xạ chúng về dạng tiếng Việt chuẩn, giúp giảm số lượng token không cần thiết.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{images/teencode.png}
    \caption{Một số từ teencode được chuẩn hóa }
    \label{fig:teencode_mapping}
\end{figure}

\subsection{Chuẩn hoá từ lặp}

Trong văn bản thu thập từ mạng xã hội, đặc biệt là văn bản thể hiện cảm xúc, những từ được cố ý kéo dài (ví dụ: ``đỉnnnhhhhh'', ``đẹppppp'', ``huuuuuu'') thường mang tính nhấn mạnh và biểu đạt mức độ cảm xúc mạnh hơn so với dạng từ gốc. Tuy nhiên, dạng kéo dài này tạo ra sự đa dạng không cần thiết trong không gian đặc trưng và làm tăng độ nhiễu của dữ liệu. Do đó cần chuẩn hoá các từ kéo dài về dạng chuẩn (ví dụ: đỉnnnhhhhh $\rightarrow$ đỉnh, đẹppppppp $\rightarrow$ đẹp, ...) nhằm giảm số lượng biến thể không có giá trị ngữ nghĩa bổ sung.

\subsection{Kết quả sau khi qua quá trình tiền xử lý}

Với dữ liệu đầu vào là:

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{images/đầu vào processor.png}
    \caption{Dữ liệu đầu vào của module processor}
    \label{fig:input_processor}
\end{figure}

Dữ liệu sau khi tiền xử lý:

\begin{table}[H]
\centering
\caption{Một số dòng dữ liệu sau khi tiền xử lý}
\renewcommand{\arraystretch}{1.3}
\begin{tabular}{c c c l c c l}
\hline
\textbf{No} & \textbf{unnamed} & \textbf{Emotion} & \textbf{Sentence} 
& \textbf{merged\_label} & \textbf{label\_id} & \textbf{processed} \\
\hline

0 & 0 & Disgust & hỏi nhạy khiếp 
& Tiêu cực & 1 & {[}“nhạy”, “khiếp”{]} \\

2 & 1944 & Surprise & con người giỏi nhỉ .
& Tích cực & 0 & {[}“con\_người”, “giỏi”{]} \\

3 & 1711 & Other & má 2 thằng áo vàng lầy ghê 
& Trung tính & 2 & {[}“má”, “2”, “thằng”, “áo”, “vàng”, “lầy”, “ghê”, “trung\_tính”{]} \\

\hline
\end{tabular}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{images/KQ module TXL.png}
    \caption{ Kết quả chạy module tiền xử lý }
    \label{fig:output_processor}
\end{figure}

%------------------------------------
\section{Module feature}
Lớp cơ sở trừu tượng (base.py)

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{images/dataFeature.png}
    \caption{Đây là khung sườn cho mọi thuật toán trích xuất đặc trưng trong hệ thống}
    \label{fig:data_feature}
\end{figure}

\begin{itemize}
    \item \textbf{Tên lớp:} \texttt{DataFeature}
    \item \textbf{Kế thừa:} \texttt{ABC} (Abstract Base Class) từ thư viện chuẩn Python.
    \item \textbf{Chức năng chính:}
    \begin{enumerate}
        \item \textbf{Thống kê dữ liệu:} Ngay khi khởi tạo, lớp này tự động tính toán số lượng từ vựng (Vocabulary Size) và tổng số lượng token trong tập dữ liệu. Điều này giúp người lập trình nắm bắt được độ phức tạp của dữ liệu đầu vào.
        \item \textbf{Định nghĩa giao diện (Interface):} Bắt buộc các lớp con phải triển khai hai phương thức cốt lõi là \texttt{fit()} và \texttt{transform()}.
    \end{enumerate}
\end{itemize}

Lớp triển khai TF-IDF (tfidf.py)

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{images/TFIDF_DF.png} % nhớ đổi tên file ngoài thư mục
    \caption{Lớp trích xuất đặc trưng TF-IDF kế thừa từ lớp cơ sở DataFeature}
    \label{fig:tfidf_feature}
\end{figure}

Đây là lớp kế thừa từ \texttt{DataFeature}, thực hiện kỹ thuật TF--IDF 
(Term Frequency -- Inverse Document Frequency).

\begin{itemize}
    \item \textbf{Tên lớp:} \texttt{TFIDF}
    \item \textbf{Thư viện sử dụng:} \texttt{TfidfVectorizer} của Scikit-learn.
    \item \textbf{Điểm kỹ thuật đặc biệt:}
    \begin{enumerate}[label=\alph*.]
        \item \textbf{Xử lý đầu vào đã tách từ (Pre-tokenized Input):}  
        Vì dữ liệu đầu vào (từ \texttt{DataProcessor}) đã được tách thành danh sách các từ 
        (list of tokens), nên \texttt{TfidfVectorizer} được cấu hình đặc biệt để không tách từ lại lần nữa.
        
        \item \textbf{Xử lý đầu vào đã tách từ:}  
        Nếu dữ liệu đầu vào đã ở dạng list of tokens, 
        \texttt{TfidfVectorizer} được cấu hình để nhận trực tiếp danh sách này 
        mà không thực hiện lại bước tách từ.
    \end{enumerate}

    \item \textbf{Cấu hình linh hoạt:}  
    Các tham số quan trọng được lấy từ file \texttt{config.py} thay vì gán cứng (hard-code),
    giúp dễ dàng tinh chỉnh mô hình:
    \begin{itemize}
        \item \texttt{max\_features}: Giới hạn số lượng từ vựng quan trọng nhất (ví dụ: 5000 từ).
        \item \texttt{ngram\_range}: Sử dụng cả từ đơn (unigram) và cụm từ (bigram, trigram).
    \end{itemize}

    \item \textbf{Quản lý lỗi và Log:}  
    Sử dụng khối try--except và hệ thống logger để ghi nhận quá trình hoạt động hoặc báo lỗi chi tiết nếu quá trình vector hóa gặp vấn đề.
\end{itemize}

%------------------------------------
\section{Tối ưu tham số}
\subsection{Logistic Regression}
Quá trình huấn luyện và đánh giá được thực hiện trên tập dữ liệu đã qua xử lý (Cleaning, Tokenization, TF-IDF) với cấu hình như sau:

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{images/LG_op.png}
    \caption{Mô hình: Logistic Regression (đã tối ưu tham số).}
    \label{fig:logistic_op}
\end{figure}

Tổng số mẫu dữ liệu: \textbf{6.241} mẫu.

Tỉ lệ phân chia:

\begin{itemize}
    \item \textbf{Tập Train (Huấn luyện)}: 4.992 mẫu (80\%).
    \item \textbf{Tập Test (Kiểm thử)}: 1.249 mẫu (20\%).
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{images/LG_test.png}
    \label{fig:logistic_test}
\end{figure}

\textbf{Phương pháp đánh giá:} Sử dụng các chỉ số Accuracy, Precision, Recall, F1-Score và Ma trận nhầm lẫn (Confusion Matrix).

\textbf{Kết quả Tổng quan}

Mô hình \textbf{Logistic Regression} sau khi tối ưu đã đạt được kết quả trên tập kiểm thử (Test set):

\\[0.2cm]
\textbf{Độ chính xác toàn cục (Overall Accuracy):} 65.09\%.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{images/LG_result.png}
    \label{fig:logistic_result}
\end{figure}

Macro Average F1-Score: 0.57.

Weighted Average F1-Score: 0.64.

\textbf{Nhận xét:}

Mức độ chính xác 65\% là một kết quả ở mức trung bình khá đối với bài toán phân loại cảm xúc 3 lớp (Tích cực, Tiêu cực, Trung tính) sử dụng các mô hình học máy truyền thống trên dữ liệu tiếng Việt. Mô hình hoạt động tốt hơn ngẫu nhiên (33\%), nhưng vẫn còn gặp khó khăn ở một số lớp dữ liệu cụ thể.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{images/LG_cm.png}
    \caption{Ma trận nhầm lẫn của mô hình Logistic Regression}
    \label{fig:logistic_cm}
\end{figure}

%-----------------------------------------------------
\subsection{Support Vector Machine}
Trong bài toán phân loại cảm xúc, hiệu quả của mô hình SVM phụ thuộc đáng kể vào bộ 
tham số siêu (hyperparameters) như \textbf{kernel}, \textbf{C}, và \textbf{gamma}. Do đó, nhóm xây dựng module 
\texttt{SVMOptimizer} nhằm tự động tìm tập tham số tốt nhất cho mô hình thông qua phương pháp 
\texttt{GridSearchCV} kết hợp đánh giá chéo (Cross-Validation).

Mục tiêu: thiết lập lưới tham số (parameter grid) cho SVM -> tìm kiếm tối ưu bằng 
GridSearchCV với thước đo \texttt{f1\_macro} (giúp đảm bảo mô hình học tốt tất cả các lớp mà 
không chỉ lớp lớn) => mô hình đạt hiệu năng cao và ổn định hơn so với việc thủ công.

Cách hoạt động của \texttt{SVMOptimizer}:
Khi khởi tạo: lớp \texttt{SVMOptimizer} nhận các tham số:
\begin{itemize}
    \item X, y là tập đặc trưng và nhãn
    \item config: chứa các thông số chung của hệ thống (random\_state, test\_size)
    \item khởi tạo bộ ghi log để theo dõi tiến trình tối ưu
\end{itemize}

Các tham số được định nghĩa như sau:

\begin{center}
\begin{tabular}{|c|c|}
\hline
\textbf{Tham số tối ưu} & \textbf{Thử nghiệm các giá trị} \\
\hline
kernel & linear, rbf, poly \\
\hline
C & 0.1, 1, 10 \\
\hline
gamma & scale, auto \\
\hline
\end{tabular}
\end{center}

Với:
\begin{itemize}
    \item kernel: quyết định hình dạng siêu phẳng
    \item C: điều chỉnh mức phạt đối với lỗi phân loại
    \item gamma: xác định mức ảnh hưởng của từng điểm dữ liệu
\end{itemize}

Tối ưu tham số bằng GridSearchCV:
\begin{itemize}
    \item Kết hợp toàn bộ các giá trị trong lưới tham số
    \item huấn luyện và đánh giá mô hình trên từng tổ hợp
    \item sử dụng k-fold cross-validation (mặc định 5-fold) để đánh giá mỗi tổ hợp
    \item chọn tổ hợp tham số cho điểm \texttt{f1\_macro} cao nhất
\end{itemize}

Kết quả trả ra:
\begin{itemize}
    \item \texttt{best\_params\_}: tham số tối ưu
    \item \texttt{best\_score\_}: điểm \texttt{f1\_macro} cao nhất đạt được
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{images/SVM_op.png}
    \caption{Kết quả tối ưu tham số của mô hình SVM}
    \label{fig:log_svm}
\end{figure}

\subsection{Naive Bayes}

Trong bài toán phân loại cảm xúc, độ hiệu quả của mô hình Naive Bayes phụ thuộc đáng kể vào
siêu tham số (hyperparameter) \texttt{alpha}. Do đó, nhóm xây dựng module 
\texttt{NaiveBayesOptimizer} nhằm thử nghiệm và tìm giá trị \texttt{alpha} tối ưu nhất thông qua 
kỹ thuật GridSearchCV kết hợp đánh giá chéo (Cross-Validation).

Mục tiêu: thiết lập lưới tham số (parameter grid) cho Naive Bayes → tìm kiếm tối ưu bằng 
GridSearchCV với thước đo \texttt{f1\_macro} (giúp đảm bảo mô hình học tốt tất cả các lớp chứ 
không chỉ lớp lớn) -> mô hình đạt hiệu năng cao và ổn định hơn so với việc thử thủ công.

Cách hoạt động của \texttt{NaiveBayesOptimizer}:

Khi khởi tạo, lớp \texttt{NaiveBayesOptimizer} nhận các tham số:
\begin{itemize}
    \item X, y: tập đặc trưng và nhãn.
    \item config: chứa các thông số chung của hệ thống (random\_state, test\_size).
    \item khởi tạo bộ ghi log để theo dõi tiến trình tối ưu.
\end{itemize}

Các tham số được định nghĩa như sau:

\begin{center}
\begin{tabular}{|c|c|}
\hline
\textbf{Tham số tối ưu} & \textbf{Thử nghiệm các giá trị} \\
\hline
alpha & 0.01, 0.1, 1.0 \\
\hline
\end{tabular}
\end{center}

Với:
\begin{itemize}
    \item \texttt{alpha}: hệ số làm trơn (smoothing) giúp tránh việc xác suất bằng 0 đối với 
    những từ hiếm trong dữ liệu.
\end{itemize}

Tối ưu tham số bằng GridSearchCV:
\begin{itemize}
    \item Kết hợp toàn bộ các giá trị trong lưới tham số.
    \item Huấn luyện và đánh giá mô hình trên từng tổ hợp.
    \item Sử dụng k-fold cross-validation (mặc định 5-fold) để đánh giá mỗi tổ hợp.
    \item Chọn tổ hợp tham số cho điểm \texttt{f1\_macro} cao nhất.
\end{itemize}

Kết quả trả ra:
\begin{itemize}
    \item \texttt{best\_params\_}: tham số tối ưu.
    \item \texttt{best\_score\_}: điểm \texttt{f1\_macro} cao nhất đạt được.
\end{itemize}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{images/NB_op.png}
    \caption{Kết quả tối ưu tham số của mô hình Naive Bayes}
    \label{fig:log_naive_bayes}
\end{figure}

Từ đó, ta thu được tham số tối ưu cho mô hình Naive Bayes: 
\texttt{alpha = 0.1} với điểm \texttt{f1\_macro = 0.5220}.

%--------------------------------------------
\section{Huấn luyện mô hình}

\subsection{Tỉ lệ phân chia (Split Ratio)}

Dữ liệu được chia thành 2 phần tách biệt với tỉ lệ 80/20 (được cấu hình trong \texttt{config.py}):

\begin{itemize}
    \item \textbf{Tập Huấn luyện (Training Set - 80\%)}: Dùng để cho mô hình học các đặc trưng và tìm ra quy luật.
    \begin{itemize}
        \item Số lượng: Khoảng 4.992 mẫu.
    \end{itemize}

    \item \textbf{Tập Kiểm thử (Test Set - 20\%)}: Dùng để đánh giá độc lập hiệu năng của mô hình sau khi học xong. Dữ liệu này mô hình chưa từng nhìn thấy trước đó (Unseen Data).
    \begin{itemize}
        \item Số lượng: Khoảng 1.249 mẫu.
    \end{itemize}
\end{itemize}

\subsection{Kỹ thuật chia: Stratified Random Sampling (Lấy mẫu phân tầng)}

Đây là điểm kỹ thuật quan trọng nhất trong phần chia dữ liệu của đồ án này.

\begin{itemize}
    \item \textbf{Vấn đề}: Dữ liệu cảm xúc thường bị mất cân bằng (Imbalanced Data). 
    Ví dụ: Nhãn \textit{``Enjoyment''} có 1000 câu, nhưng \textit{``Fear''} chỉ có 100 câu. 
    Nếu chia ngẫu nhiên bình thường, có thể xảy ra trường hợp tập Test không có câu \textit{``Fear''} nào, hoặc tỉ lệ bị lệch hẳn so với thực tế.
    
    \item \textbf{Giải pháp}: Sử dụng tham số \texttt{stratify=self.y} trong hàm \texttt{train\_test\_split}.
    
    \item \textbf{Tác dụng}: Đảm bảo tỉ lệ phần trăm của các nhãn (Vui, Buồn, Giận...) trong tập Train và tập Test là giống hệt nhau và giống với tập dữ liệu gốc.
\end{itemize}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{images/KyThuatChia.png}
    \caption{Minh họa kỹ thuật Stratified Random Sampling}
    \label{fig:stratified_sampling}
\end{figure}

\subsection{Logistic Regression}
Mô hình \textbf{Logistic Regression} được lựa chọn làm mô hình cơ sở (Baseline Model) cho bài toán phân loại cảm xúc đa lớp (Multi-class Classification) với 3 nhãn chính: Tích cực, Tiêu cực, và Trung tính (hoặc 7 nhãn chi tiết tùy theo cấu hình tập dữ liệu).

Quy trình huấn luyện được thực hiện theo các bước chuẩn:

\begin{enumerate}
    \item \textbf{Đầu vào:} Ma trận đặc trưng TF-IDF (được tạo từ \texttt{feature\_layer/tfidf.py}).
    
    \item \textbf{Chia dữ liệu:} Tập dữ liệu được chia theo tỉ lệ 80\% Huấn luyện -- 20\% Kiểm thử.  
    Quá trình chia sử dụng kỹ thuật \textit{Stratified Sampling} (lấy mẫu phân tầng) để đảm bảo tỉ lệ các nhãn cảm xúc được giữ nguyên, tránh hiện tượng lệch pha dữ liệu.
    
    \item \textbf{Huấn luyện:} Sử dụng thuật toán tối ưu hóa \texttt{lbfgs} (Limited-memory BFGS) phù hợp cho các bài toán đa lớp.
\end{enumerate}

Các chỉ số đánh giá được sử dụng:

\begin{itemize}
    \item \textbf{Accuracy (Độ chính xác):} Tỉ lệ dự đoán đúng trên tổng số mẫu.
    
    \item \textbf{Precision (Độ chính xác theo lớp):} Trong số các mẫu dự đoán là "Tiêu cực", bao nhiêu phần trăm là đúng?
    
    \item \textbf{Recall (Độ nhạy):} Mô hình tìm được bao nhiêu phần trăm các mẫu "Tiêu cực" có trong thực tế?
    
    \item \textbf{F1-Score:} Trung bình điều hòa giữa Precision và Recall. Đây là chỉ số quan trọng nhất vì dữ liệu cảm xúc thường mất cân bằng.
\end{itemize}

\subsection{Support Vector Machine}
Module SVM Model triển khai toàn bộ pipeline huấn luyện mô hình SVM cho bài toán phân loại cảm xúc, bao gồm chia dữ liệu, cân bằng lớp bằng RandomOverSampler, huấn luyện bằng SVC, đánh giá bằng classification report và lưu/khôi phục mô hình bằng joblib. Mô hình sử dụng tham số kernel và C từ file cấu hình nhằm đảm bảo tính nhất quán và khả năng tái sử dụng. Quá trình xử lý được giám sát thông qua hệ thống logging, giúp dễ dàng kiểm tra và theo dõi kết quả. 

\subsection{Naive Bayes}
Module Naive Bayes Model triển khai toàn bộ pipeline huấn luyện mô hình Naive Bayes cho bài toán phân loại cảm xúc, bao gồm chia dữ liệu, cân bằng lớp bằng RandomOverSampler, huấn luyện mô hình bằng thuật toán MultinomialNB, đánh giá bằng classification report và lưu/khôi phục mô hình bằng joblib. Mô hình sử dụng tham số \texttt{alpha} được lấy từ file cấu hình nhằm đảm bảo tính nhất quán và khả năng tái sử dụng. Toàn bộ quá trình xử lý được giám sát thông qua hệ thống logging, giúp dễ dàng kiểm tra và theo dõi kết quả.
